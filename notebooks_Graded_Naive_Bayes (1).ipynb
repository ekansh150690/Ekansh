{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "anaconda-cloud": {}
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Multinomial and Bernoulli Naive Bayes",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For understanding Multinomial and Bernoulli Naive Bayes, we will start with a small example and understand the end to end process. In another notebook, we will build a full-fledged email spam classifier.\n\nTo start with, let's take a few sentences and classify them in two different classes - *education* or *cinema*. Each sentence will represent one document. In real-world cases, a document be any piece of text such as an email, a news article, a book review, a tweet etc.\nThe analysis and the algorithm involved doesn’t depend on the type of document we use.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The notebook is divided into the following sections:\n1. Importing and preprocessing data\n2. Building the model: Multinomial Naive Bayes\n3. Building the model: Bernoulli Naive Bayes",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 1. Importing and Preprocessing Data\n\nLet us first look at the sentences and their classes. We have kept the training sentences in file example_train.csv. Test sentences have been put in the file example_test.csv.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "python -m pip install --upgrade pandas\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'SyntaxError'>",
          "evalue": "invalid syntax (<ipython-input-2-e1650e35706c>, line 1)",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python -m pip install --upgrade pandas\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "\nimport numpy as np\nimport pandas as pd\nimport sklearn\n\n# training data\n#train_docs = pd.read_table('movie_review_train.csv', header=None, names=['class', 'text'])\ntrain_docs = pd.read_csv('movie_review_train.csv') \ntrain_docs\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-3-e00beeb86e65>:2: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        },
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     class                                               text\n0      Pos   a common complaint amongst film critics is   ...\n1      Pos   whew   this film oozes energy   the kind of b...\n2      Pos   steven spielberg s   amistad     which is bas...\n3      Pos   he has spent his entire life in an awful litt...\n4      Pos   being that it is a foreign language film with...\n...    ...                                                ...\n1595   Neg   if anything     stigmata   should be taken as...\n1596   Neg   john boorman s   zardoz   is a goofy cinemati...\n1597   Neg   the kids in the hall are an acquired taste   ...\n1598   Neg   there was a time when john carpenter was a gr...\n1599   Neg   two party guys bob their heads to haddaway s ...\n\n[1600 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pos</td>\n      <td>a common complaint amongst film critics is   ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pos</td>\n      <td>whew   this film oozes energy   the kind of b...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pos</td>\n      <td>steven spielberg s   amistad     which is bas...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pos</td>\n      <td>he has spent his entire life in an awful litt...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pos</td>\n      <td>being that it is a foreign language film with...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>Neg</td>\n      <td>if anything     stigmata   should be taken as...</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>Neg</td>\n      <td>john boorman s   zardoz   is a goofy cinemati...</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>Neg</td>\n      <td>the kids in the hall are an acquired taste   ...</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>Neg</td>\n      <td>there was a time when john carpenter was a gr...</td>\n    </tr>\n    <tr>\n      <th>1599</th>\n      <td>Neg</td>\n      <td>two party guys bob their heads to haddaway s ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1600 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "So as you can see there are 5 documents (sentences) , 3 are of \"education\" class and 2 are of \"cinema\" class.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# convert label to a numerical variable\ntrain_docs['class'] = train_docs['class'].map({'Neg':0, 'Pos':1})\ntrain_docs\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      class                                               text\n0         1   a common complaint amongst film critics is   ...\n1         1   whew   this film oozes energy   the kind of b...\n2         1   steven spielberg s   amistad     which is bas...\n3         1   he has spent his entire life in an awful litt...\n4         1   being that it is a foreign language film with...\n...     ...                                                ...\n1595      0   if anything     stigmata   should be taken as...\n1596      0   john boorman s   zardoz   is a goofy cinemati...\n1597      0   the kids in the hall are an acquired taste   ...\n1598      0   there was a time when john carpenter was a gr...\n1599      0   two party guys bob their heads to haddaway s ...\n\n[1600 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>a common complaint amongst film critics is   ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>whew   this film oozes energy   the kind of b...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>steven spielberg s   amistad     which is bas...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>he has spent his entire life in an awful litt...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>being that it is a foreign language film with...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>0</td>\n      <td>if anything     stigmata   should be taken as...</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>0</td>\n      <td>john boorman s   zardoz   is a goofy cinemati...</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>0</td>\n      <td>the kids in the hall are an acquired taste   ...</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>0</td>\n      <td>there was a time when john carpenter was a gr...</td>\n    </tr>\n    <tr>\n      <th>1599</th>\n      <td>0</td>\n      <td>two party guys bob their heads to haddaway s ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1600 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "Let's now split the dataframe into X and y labels.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# convert the df to a numpy array \ntrain_array = train_docs.values\n\n# split X and y\nX_train = train_array[:,1]\ny_train = train_array[:,0]\ny_train = y_train.astype('int') # sklearn needs y as integers\n\n#print(\"X_train\")\n#print(X_train)\nprint(\"y_train\")\nprint(y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "y_train\n[1 1 1 ... 0 0 0]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "### Creating the Bag of Words Representation\n\nWe now have to convert the data into a format which can be used for training the model. We'll use the **bag of words representation** for each sentence (document).\n\nImagine breaking X in individual words and putting them all in a bag. Then we pick all the unique words from the bag one by one and make a dictionary of unique words. \n\nThis is called **vectorization of words**. We have the class ```CountVectorizer()``` in scikit learn to vectorize the words. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# create an object of CountVectorizer() class \nfrom sklearn.feature_extraction.text import CountVectorizer \n# help(CountVectorizer)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "vec = CountVectorizer()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "Here ```vec``` is an object of class ```CountVectorizer()```. This has a method called  ```fit()``` which converts a corpus of documents to a matrix of 'tokens'.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# fit the vectorizer on training data \nvec.fit(X_train)\n#vec.vocabulary_",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CountVectorizer()",
            "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "```Countvectorizer()``` has converted the documents into a set of unique words alphabetically sorted and indexed.\n\n\n**Stop Words**\n\nWe can see a few trivial words such as  'and','is','of', etc. These words don't really make any difference in classyfying a document. These are called **stop words**. So we would like to get rid of them. \n\nWe can remove them by passing a parameter stop_words='english' while instantiating ```Countvectorizer()``` as follows: ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# fitting the vectorizer on training data again\n# removing the stop words this time\nvec = CountVectorizer(stop_words='english')\nvec.fit(X_train)\nlen(vec.vocabulary_)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "35858"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "# fitting the vectorizer on training data again\n# removing the stop words this time\nvec = CountVectorizer(stop_words='english', min_df=.03, max_df=.8)\nvec.fit(X_train)\nlen(vec.vocabulary_)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "1643"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "Notice that the vocabulary has reduced to 12 from 15. Another way of printing the 'vocabulary' is as follows:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# printing feature names\nprint(vec.get_feature_names_out())\nprint(len(vec.get_feature_names_out()))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['000' '10' '100' ... 'york' 'young' 'younger']\n1643\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "# another way of representing the features\nX_transformed = vec.transform(X_train)\nX_transformed",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<1600x1643 sparse matrix of type '<class 'numpy.int64'>'\n\twith 217396 stored elements in Compressed Sparse Row format>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "print(X_transformed)",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "  (0, 4)\t1\n  (0, 59)\t2\n  (0, 72)\t1\n  (0, 78)\t1\n  (0, 81)\t1\n  (0, 99)\t3\n  (0, 101)\t1\n  (0, 192)\t1\n  (0, 211)\t1\n  (0, 213)\t1\n  (0, 220)\t1\n  (0, 264)\t2\n  (0, 287)\t1\n  (0, 316)\t1\n  (0, 323)\t1\n  (0, 328)\t1\n  (0, 340)\t1\n  (0, 342)\t1\n  (0, 357)\t1\n  (0, 386)\t1\n  (0, 413)\t2\n  (0, 445)\t2\n  (0, 464)\t1\n  (0, 503)\t1\n  (0, 506)\t1\n  :\t:\n  (1599, 1247)\t1\n  (1599, 1258)\t2\n  (1599, 1267)\t1\n  (1599, 1271)\t1\n  (1599, 1331)\t1\n  (1599, 1335)\t1\n  (1599, 1339)\t1\n  (1599, 1366)\t3\n  (1599, 1371)\t1\n  (1599, 1375)\t1\n  (1599, 1379)\t1\n  (1599, 1413)\t1\n  (1599, 1421)\t1\n  (1599, 1429)\t2\n  (1599, 1447)\t1\n  (1599, 1501)\t1\n  (1599, 1533)\t1\n  (1599, 1550)\t1\n  (1599, 1555)\t1\n  (1599, 1556)\t1\n  (1599, 1570)\t1\n  (1599, 1579)\t2\n  (1599, 1589)\t1\n  (1599, 1609)\t1\n  (1599, 1616)\t1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": "This representation can be understood as follows:\n\nConsider first 4 rows of the output: (0,2), (0,5), (0,7) and (0,11). It says that the first document (index 0) has \n7th , 2nd , 5th and 11th 'word' present in the document, and that they appear only\nonce in the document- indicated by the right hand column entry. \n\nSimilarly, consider the entry (4,4) (third from bottom). It says that the fifth document has the fifth word present twice. Indeed, the 5th word('good') appears twice in the 5th document. \n\nIn real problems, you often work with large documents and vocabularies, and each document contains only a few words in the vocabulary. So it would be a waste of space to store the vocabulary in a typical dataframe, since most entries would be zero. Also, matrix products, additions etc. are much faster with sparse matrices. That's why we use sparse matrices to store the data.\n\n\nLet us convert this sparse matrix into a more easily interpretable array:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# converting transformed matrix back to an array\n# note the high number of zeros\nX_transformed.toarray()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": "To make the dataset more readable, let us examine the vocabulary and the document-term matrix together in a pandas dataframe. The way to convert a matrix into a dataframe is ```pd.DataFrame(matrix, columns=columns)```.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# converting matrix to dataframe\npd.DataFrame(X_transformed.toarray(), \n             columns=vec.get_feature_names_out())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      000  10  100  13  15  1995  1996  1997  1998  1999  ...  written  wrong  \\\n0       0   0    0   0   1     0     0     0     0     0  ...        0      0   \n1       0   0    0   0   0     0     0     0     0     0  ...        0      0   \n2       0   0    0   0   0     0     0     0     0     0  ...        0      1   \n3       0   0    0   0   0     0     0     0     0     0  ...        0      0   \n4       0   1    0   0   0     0     0     0     0     0  ...        0      0   \n...   ...  ..  ...  ..  ..   ...   ...   ...   ...   ...  ...      ...    ...   \n1595    0   0    0   0   0     0     0     0     0     0  ...        0      0   \n1596    0   0    0   0   0     0     0     0     0     0  ...        0      0   \n1597    0   0    0   0   0     0     0     0     0     0  ...        0      0   \n1598    0   0    0   0   0     2     1     0     0     0  ...        1      1   \n1599    0   0    0   0   0     0     0     0     0     0  ...        0      0   \n\n      wrote  yeah  year  years  yes  york  young  younger  \n0         0     0     0      3    0     0      0        0  \n1         0     0     0      0    1     0      0        0  \n2         0     0     1      0    0     0      0        0  \n3         0     0     0      1    0     0      1        0  \n4         0     0     0      0    0     0      0        0  \n...     ...   ...   ...    ...  ...   ...    ...      ...  \n1595      0     0     2      0    1     0      0        0  \n1596      0     0     1      1    0     0      0        0  \n1597      0     0     0      0    0     0      0        0  \n1598      0     0     0      0    0     0      0        0  \n1599      0     0     0      0    0     0      0        0  \n\n[1600 rows x 1643 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>000</th>\n      <th>10</th>\n      <th>100</th>\n      <th>13</th>\n      <th>15</th>\n      <th>1995</th>\n      <th>1996</th>\n      <th>1997</th>\n      <th>1998</th>\n      <th>1999</th>\n      <th>...</th>\n      <th>written</th>\n      <th>wrong</th>\n      <th>wrote</th>\n      <th>yeah</th>\n      <th>year</th>\n      <th>years</th>\n      <th>yes</th>\n      <th>york</th>\n      <th>young</th>\n      <th>younger</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1599</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1600 rows × 1643 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": "This table shows how many times a particular word occurs in document. In other words, this is a frequency table of the words.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "A corpus of documents can thus be represented by a matrix with one row per document and one column per\ntoken (e.g. word) occurring in the corpus.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's now import and transform the test data as well.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# test data\ntest_docs = pd.read_csv('movie_review_test.csv') \ntest_docs",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "    class                                               text\n0     Pos   films adapted from comic books have had plent...\n1     Pos   every now and then a movie comes along from a...\n2     Pos   you ve got mail works alot better than it des...\n3     Pos      jaws   is a rare film that grabs your atte...\n4     Pos   moviemaking is a lot like being the general m...\n..    ...                                                ...\n395   Neg   one of the first films of 1999 is this mtv pi...\n396   Neg   susan granger s review of   america s sweethe...\n397   Neg   susan granger s review of   jeepers creepers ...\n398   Neg   this independent film written and directed by...\n399   Neg   come on hollywood   surprise me    stop givin...\n\n[400 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pos</td>\n      <td>films adapted from comic books have had plent...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pos</td>\n      <td>every now and then a movie comes along from a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pos</td>\n      <td>you ve got mail works alot better than it des...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pos</td>\n      <td>jaws   is a rare film that grabs your atte...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pos</td>\n      <td>moviemaking is a lot like being the general m...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>Neg</td>\n      <td>one of the first films of 1999 is this mtv pi...</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>Neg</td>\n      <td>susan granger s review of   america s sweethe...</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>Neg</td>\n      <td>susan granger s review of   jeepers creepers ...</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>Neg</td>\n      <td>this independent film written and directed by...</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>Neg</td>\n      <td>come on hollywood   surprise me    stop givin...</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": "# convert label to a numerical variable\ntest_docs['class'] = test_docs['class'].map({'Neg':0, 'Pos':1})\ntest_docs",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     class                                               text\n0        1   films adapted from comic books have had plent...\n1        1   every now and then a movie comes along from a...\n2        1   you ve got mail works alot better than it des...\n3        1      jaws   is a rare film that grabs your atte...\n4        1   moviemaking is a lot like being the general m...\n..     ...                                                ...\n395      0   one of the first films of 1999 is this mtv pi...\n396      0   susan granger s review of   america s sweethe...\n397      0   susan granger s review of   jeepers creepers ...\n398      0   this independent film written and directed by...\n399      0   come on hollywood   surprise me    stop givin...\n\n[400 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>films adapted from comic books have had plent...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>every now and then a movie comes along from a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>you ve got mail works alot better than it des...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>jaws   is a rare film that grabs your atte...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>moviemaking is a lot like being the general m...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>0</td>\n      <td>one of the first films of 1999 is this mtv pi...</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>0</td>\n      <td>susan granger s review of   america s sweethe...</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>0</td>\n      <td>susan granger s review of   jeepers creepers ...</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>0</td>\n      <td>this independent film written and directed by...</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>0</td>\n      <td>come on hollywood   surprise me    stop givin...</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": "# convert to numpy array\ntest_numpy_array = test_docs.values\n\n# split into X and y\nX_test = test_numpy_array[:,1]\ny_test = test_numpy_array[:,0]\n\nprint(\"X_test\")\n#print(X_test)\nprint(\"y_test\")\n#print(y_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "X_test\ny_test\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": "# transform the test data\n# note that you *never* fit on test data, only on training data\n# and only transform the test data\nX_test_transformed = vec.transform(X_test)\nX_test_transformed",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<400x1643 sparse matrix of type '<class 'numpy.int64'>'\n\twith 51663 stored elements in Compressed Sparse Row format>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": "# convert to non-sparse array\nX_test=X_test_transformed.toarray()\nX_test\n# Count the non-zero values\nnon_zero_count = np.count_nonzero(X_test)\nprint(\"Number of non-zero values:\", non_zero_count)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of non-zero values: 51663\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "Let us summarise all we have done till now:\n\n- ```vect.fit(train)``` learns the vocabulary of the training data\n- ```vect.transform(train)``` uses the fitted vocabulary to build a document-term matrix from the training data\n- ```vect.transform(test)``` uses the fitted vocabulary to build a document-term matrix from the testing data (and ignores tokens it hasn't seen before)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 2. Building the Model: Multinomial Naive Bayes",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# building a multinomial NB model\nfrom sklearn.naive_bayes import MultinomialNB\n\n# instantiate NB class\nmnb=MultinomialNB()\n\n# fitting the model on training data\nmnb.fit(X_transformed, y_train)\n\n# note that we are using the sparse matrix X_transformed, \n# though you can also use the non-sparse version\n# mnb.fit(X_transformed.toarray(), y_train) \n\n# predicting probabilities of test data\nproba = mnb.predict_proba(X_test)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": "# probability of each class (test data)\n#print(\"probability of test document belonging to class Neg\" , proba[:,1])\n#print(\"probability of test document belonging to class Pos\" , proba[:,0])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 65
    },
    {
      "cell_type": "markdown",
      "source": "### 3. Building the Model: Bernoulli Naive Bayes",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(np.unique(y_train))\nprint(np.unique(y_test))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0 1]\n[0 1]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": "y_train = y_train.astype(int)\ny_test = y_test.astype(int)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import BernoulliNB\n\n# instantiate bernoulli NB object\nbnb = BernoulliNB()\n\n# fit \nbnb.fit(X_transformed,y_train)\n\n# predict class\ny_pred_class = bnb.predict(X_test_transformed)\n\n# predict probability\ny_pred_proba =bnb.predict_proba(X_test_transformed)\n\n# accuracy\nfrom sklearn import metrics\nmetrics.accuracy_score(y_test, y_pred_class)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.79"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": "In the next notebook, we will use Multinomial and Bernoulli Naive Bayes to solve an interesting real problem - classifying SMSes as spam or ham. We'll also see how to decide the optimal cutoff probability and evaluate the model.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "metrics.confusion_matrix(y_test, y_pred_class)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[177,  23],\n       [ 61, 139]], dtype=int64)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}